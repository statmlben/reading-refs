Optimization
--------

12-19 [Minimizing a Quadratic over A Sphere](http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf)

12-19 [Quadratic Programming Over Ellipsoids](https://arxiv.org/pdf/1711.04401.pdf)

01-20 [Non-Convex Matrix Completion and Related Problems via Strong Duality](http://www.jmlr.org/papers/volume20/17-611/17-611.pdf)

01-20 [Scalable Interpretable Multi-Response Regression via SEED](http://www.jmlr.org/papers/volume20/18-200/18-200.pdf)

01-20 [Optimization for deep learning: theory and algorithms](https://arxiv.org/pdf/1912.08957.pdf)

02-20 [Convergence Guarantees for a Class of Non-convex and Non-smooth Optimization Problems
](http://www.jmlr.org/papers/volume20/18-762/18-762.pdf)

02-20 [Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals](http://www.jmlr.org/papers/volume20/18-616/18-616.pdf)

02-20 [Gradient Descent Finds Global Minima of Deep Neural Networks](https://arxiv.org/pdf/1811.03804.pdf)

02-20 [Towards moderate overparameterization: global convergence guarantees for training shallow neural networks](https://arxiv.org/pdf/1902.04674.pdf)

02-20 [Global optimality conditions for deep neural networks](https://openreview.net/pdf?id=BJk7Gf-CZ)

02-20 [Target Propagation in Recurrent Neural Networks](http://jmlr.org/papers/volume21/18-141/18-141.pdf)

03-20 [Elimination of All Bad Local Minima in Deep Learning](https://arxiv.org/pdf/1901.00279.pdf)

04-20 [Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk Minimization](https://arxiv.org/pdf/1907.04371.pdf)

04-20 [A Unified Convergence Analysis of Block Successive Minimization Methods for Nonsmooth Optimization](https://arxiv.org/pdf/1209.2385.pdf)

04-20 [On Faster Convergence of Cyclic Block Coordinate Descent-type Methods for Strongly Convex Minimization](http://www.jmlr.org/papers/volume18/17-157/17-157.pdf)

04-20 [Biconvex Sets and Optimization with Biconvex Functions - A Survey and Extensions](http://www2.math.uni-wuppertal.de/~klamroth/publications/gopfkl07.pdf)

06-01 [Deep Learning without Poor Local Minima](http://papers.nips.cc/paper/6112-deep-learning-without-poor-local-minima.pdf)

06-20 [Spurious local minima exist for almost all over-parameterized neural networks.](https://arxiv.org/pdf/1911.01413.pdf)

06-20 [How Does Batch Normalization Help Optimization?](https://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf)

06-20 [Musings on Deep Learning: Properties of SGD](https://cbmm.mit.edu/sites/default/files/publications/CBMM-Memo-067-v4.pdf)

06-20 [AUC Optimization vs. Error Rate Minimization](https://papers.nips.cc/paper/2518-auc-optimization-vs-error-rate-minimization.pdf)

06-20 [Non-Convex Learning via Stochastic Gradient Langevin Dynamics: A Nonasymptotic Analysis](https://arxiv.org/pdf/1702.03849.pdf)

07-20 [Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization](https://papers.nips.cc/paper/7575-global-convergence-of-langevin-dynamics-based-algorithms-for-nonconvex-optimization.pdf)

07-20 [The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization](https://papers.nips.cc/paper/8136-the-limit-points-of-optimistic-gradient-descent-in-min-max-optimization.pdf)

07-20 [Non-Convex Min-Max Optimization: Provable Algorithms and Applications in Machine Learning](https://arxiv.org/pdf/1810.02060.pdf)

07-20 [Convergence Properties of the K-Means Algorithms](http://papers.nips.cc/paper/989-convergence-properties-of-the-k-means-algorithms.pdf)

08-20 [A Variational Perspective on Accelerated Methods in Optimization](https://arxiv.org/pdf/1603.04245.pdf)

08-20 [EM Converges for a Mixture of Many Linear Regressions](http://proceedings.mlr.press/v108/kwon20a/kwon20a.pdf)

09-20 [Gradient descent with non-convex constraints: local concavity determines convergence](https://watermark.silverchair.com/iay002.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqQwggKgBgkqhkiG9w0BBwagggKRMIICjQIBADCCAoYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM46X6JaB2LOe1n5QuAgEQgIICV5NlS3ArTuiCfcYfQSU8DGR-YorDaOSCR9v6NaRS53LbOwSrCWKFPJITWCZE_aHUosMoWYKQ_cxpmcySdzxbM8lA7LQi1s5OMAdFC8IYzUEaiIEtGIaQHyMPJa30lU8oqggOZTb2WSAYBKpjdyY-jDhtbJfBjppQsGs5eQ5OcBPRFn0rNNf4gADs6FSDBqb3BuZGrA0inGP2j_g6KQbeqUl7MOuMzHrwjg4GRJ8tjoa7NTZ8wfsDlX6EHISOjVYGZwP73bWr3a0J0Y3hLuE-26eTBIh_8B693f_tvbayzSI1Vui-2vbSfb9gOMF_odA-KOlbuNgK2vS0OoQtEORd6vnxNd42VPzzXzZuXeuNTeFg8X17K9btv8Pq6MXA_gG3h7AdO1QpaP4vKCbFQnVzq_9-apIRA97NIg8IaW_grc-Yw37Jgl6VebgNnSpvoSpqw0zbnR_9pKLfIyg97ZwadiSNi-OTewu4Kwjr31YzeZotGw849JZJkbeLPmqhWlpBKJd6Yie70jQSL5nY8mnEpzBKvTvLCakuXHgEjhLwpGKP8qaBNvy1GmluNYFVB3SGjuMscTZFwIT7BZi4aj6x2wXLia_YyiW9GwZkJqF-fW2BETENOFoXytqn7kM8t1hc_MdLQPk6gHnQ9zL1F1R1_j6FLBgwrePCLD366iFU-PnE9bCvDt_yfJQyQKnDAhjZxMU-j0tb3sT7SifrfkjIIZryBDQ354lsHcfhHSo7GOZso6crAWBHDuQWjS-GXEhBX1EqDDB2tmeMnBwjJ1N6zRkGW3d6xZzA)

09-20 [Stochastic Successive Convex Approximation for Non-Convex Constrained Stochastic Optimization](https://arxiv.org/pdf/1801.08266.pdf)

09-20 [Lp-Box ADMM: A Versatile Framework for Integer Programming](https://ieeexplore.ieee.org/document/8378001)

09-20 [Local Feature Selection for Data Classification](https://ccc.inaoep.mx/~ariel/Local%20Feature%20Selection%20for%20Data%20Classification.pdf)

10-20 [extreme points in concave programming](https://scicomp.stackexchange.com/questions/10676/minimizing-a-negative-definite-quadratic-function-with-specified-bounds)

10-20 [Convergence analysis for coordinate descent](http://www.stat.cmu.edu/~ryantibs/convexopt-S15/lectures/22-coord-desc.pdf)

12-20 [Optimization by gradient boosting](https://arxiv.org/pdf/1707.05023.pdf)

12-20 [Better Theory for SGD in the Nonconvex World](https://arxiv.org/pdf/2002.03329.pdf)

12-20 [Theory of Deep Learning IIb: Optimization Properties of SGD](https://arxiv.org/pdf/1801.02254.pdf)
