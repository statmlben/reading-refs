# Reading references

Statistical learning theory
------
12-19 [Calculus of variation](https://www.reed.edu/physics/faculty/wheeler/documents/Classical%20Field%20Theory/Class%20Notes/Field%20Theory%20Chapter%205.pdf)

12-19 [On Methods of Sieves And Penalization](https://projecteuclid.org/download/pdf_1/euclid.aos/1030741085)

12-19 [Reconciling modern machine learning practice and the bias-variance trade-off](https://arxiv.org/abs/1812.11118)

12-19 [Deep Double Descent: Where Bigger Models and More Data Hurt](https://arxiv.org/pdf/1912.02292.pdf)

12-19 [How Much Over-parameterization Is Sufficient to Learn
Deep ReLU Networks?](https://arxiv.org/pdf/1911.12360.pdf)

01-19 [Concentration inequalities and asymptotic results for ratio type empirical processes](https://projecteuclid.org/euclid.aop/1151418495)

06-19 [Benign Overfitting in Linear Regression](https://arxiv.org/abs/1906.11300)

01-20 [Fantastic Generalization Measures and Where to Find Them](https://arxiv.org/pdf/1912.02178.pdf)

01-20 [Understanding Deep Double Descent](https://www.lesswrong.com/posts/FRv7ryoqtvSuqBxuT/understanding-deep-double-descent)

01-20 [Boosted Kernel Ridge Regression: Optimal Learning Rates and Early Stopping](http://www.jmlr.org/papers/volume20/18-063/18-063.pdf)

01-20 [Tunability: Importance of Hyperparameters of Machine Learning Algorithms](http://www.jmlr.org/papers/volume20/18-444/18-444.pdf)

01-20 [Variance-based Regularization with Convex Objectives](http://www.jmlr.org/papers/volume20/17-750/17-750.pdf)

01-20 [Deep Optimal Stopping](http://www.jmlr.org/papers/volume20/18-232/18-232.pdf)

01-20 [Spectrally-normalized margin bounds for neural networks](https://arxiv.org/pdf/1706.08498.pdf)

01-20 [Consistency of the MLE under mixture models](https://arxiv.org/pdf/1607.01251.pdf)

01-20 [Unbiased Generative Semi-Supervised Learning](http://jmlr.csail.mit.edu/papers/volume15/foxroberts14a/foxroberts14a.pdf)

01-20 [The Effect of Model Misspecification on Semi-Supervised Classification](https://ieeexplore.ieee.org/document/5728822)

01-20 [Spectral method and regularized MLE are both optimal for top-K ranking](https://projecteuclid.org/download/pdfview_1/euclid.aos/1558425643)

Methodology
------
12-19 [AR-Net: A simple Auto-Regressive Neural Network for time-series
](https://arxiv.org/pdf/1911.12436.pdf)

12-19 [Self-Taught Object Localization with Deep Networks](https://arxiv.org/pdf/1409.3964.pdf)

12-19 [Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks](https://arxiv.org/pdf/1809.03193.pdf)

09-19 [YOLOv3: An Incremental Improvement](https://arxiv.org/pdf/1804.02767.pdf)

09-19 [Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150)

09-19 [Are we really making much progress? A worrying analysis of recent neural recommendation approaches](https://dl.acm.org/doi/10.1145/3298689.3347058)

10-19 [Robust Bi-Tempered Logistic Loss Based on Bregman Divergences](https://arxiv.org/pdf/1906.03361.pdf)

12-19 [AP-Perf: Incorporating Generic Performance Metrics in Differentiable Learning](https://arxiv.org/pdf/1912.00965.pdf)

12-19 [Practical Bayesian Optimization of Machine Learning Algorithms](http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf)
- code: https://github.com/fmfn/BayesianOptimization

02-19 [Domain-Adversarial Training of Neural Networks](http://www.jmlr.org/papers/volume17/15-239/15-239.pdf)

01-20 [Distribution-Independent PAC Learning of Halfspaces with Massart Noise](https://arxiv.org/pdf/1906.10075.pdf)

01-20 [Near Optimal Frequent Directions for Sketching Dense and Sparse Matrices](http://www.jmlr.org/papers/volume20/18-875/18-875.pdf)

01-20 [An Efficient Two Step Algorithm for High Dimensional
Change Point Regression Models Without Grid Search](http://www.jmlr.org/papers/volume20/18-460/18-460.pdf)

01-20 [Semi-Supervised Learning with Deep Generative Models
](https://arxiv.org/abs/1406.5298)

01-20 [Semi-supervised Learning by Entropy Minimization](http://papers.nips.cc/paper/2740-semi-supervised-learning-by-entropy-minimization.pdf)

01-20 [Reliable Decision Support using Counterfactual Models](https://arxiv.org/pdf/1703.10651.pdf)

01-20 [Improved Variational Inference with Inverse Autoregressive Flow](https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow.pdf)

01-20 [Learning to Classify Ordinal Data: The Data Replication Method](http://www.jmlr.org/papers/volume8/cardoso07a/cardoso07a.pdf)

01-20 [Classification with imperfect training labels](https://arxiv.org/pdf/1805.11505.pdf)

Optimization
--------

12-19 [Minimizing a Quadratic over A Sphere](http://users.clas.ufl.edu/hager/papers/Regular/sphere.pdf)

12-19 [Quadratic Programming Over Ellipsoids](https://arxiv.org/pdf/1711.04401.pdf)

01-20 [Non-Convex Matrix Completion and Related Problems via Strong Duality](http://www.jmlr.org/papers/volume20/17-611/17-611.pdf)

01-20 [Scalable Interpretable Multi-Response Regression via SEED](http://www.jmlr.org/papers/volume20/18-200/18-200.pdf)

01-20 [Optimization for deep learning: theory and algorithms](https://arxiv.org/pdf/1912.08957.pdf)

Inference
--------
12-19 [Quadratic Form of Random Variable](http://pages.stat.wisc.edu/~st849-1/lectures/Ch02.pdf)

12-19 [The Likelihood Ratio Test in High-dimensional Logistic Regression is Asymptotically a Rescaled Chi-square](https://link.springer.com/content/pdf/10.1007%2Fs00440-018-00896-9.pdf)

12-19 [On High-dimensional Constrained Maximum Likelihood Inference](https://www.asc.ohio-state.edu/zhu.219/manuscript/inference.pdf)

01-20 [Fisher sharp null hypothesis](https://stats.stackexchange.com/questions/281200/is-fisher-sharp-null-hypothesis-testable)

01-20 [Double/debiased machine learning for treatment and structural parameters](https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097)

Coding
--------
12-19 [scikit-multilearn: A scikit-based Python environment for
performing multi-label classification](http://www.jmlr.org/papers/volume20/17-100/17-100.pdf)

12-19 [Fine-tuned BERT in Keras with Tensorflow hub](https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b)

12-19 [Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes](https://arxiv.org/pdf/1910.12478.pdf)

01-20 [PyOD: A Python Toolbox for Scalable Outlier Detection](http://www.jmlr.org/papers/volume20/19-011/19-011.pdf)

01-20 [imbalanced-learning](https://github.com/scikit-learn-contrib/imbalanced-learn#id23)

01-20 [Surpriselib: Python Library for Recommender System](http://surpriselib.com/)
